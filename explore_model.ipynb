{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuneable Params\n",
    "lr = 1e-3\n",
    "data_dir = \"data_3_class\"\n",
    "model_name = \"b0\"\n",
    "save_logs = True\n",
    "epochs = 100\n",
    "rotate_angle=None\n",
    "horizontal_flip_prob=None\n",
    "brightess_contrast=None\n",
    "gaussian_blur=None\n",
    "normalize=True\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "results_folder_name = \"3_class_results_leaky\"\n",
    "truncated_layers = 0\n",
    "bootstrap_n = 1000\n",
    "pretrained = True\n",
    "image_size = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded EfficientNet b0.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import EfficientNet_B0_Weights, EfficientNet_B1_Weights, EfficientNet_B2_Weights, EfficientNet_B3_Weights\n",
    "\n",
    "# Define the model mapping as a constant (outside the function)\n",
    "MODEL_MAPPING = {\n",
    "    \"b0\": (\"efficientnet_b0\", EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
    "    \"b1\": (\"efficientnet_b1\", EfficientNet_B1_Weights.IMAGENET1K_V1),\n",
    "    \"b2\": (\"efficientnet_b2\", EfficientNet_B2_Weights.IMAGENET1K_V1),\n",
    "    \"b3\": (\"efficientnet_b3\", EfficientNet_B3_Weights.IMAGENET1K_V1),\n",
    "}\n",
    "\n",
    "def load_efficientnet(model_name, model_mapping, pretrained):\n",
    "    \"\"\"\n",
    "    Load an EfficientNet model based on the provided model name and model mapping.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the EfficientNet model (e.g., \"b0\", \"b1\", \"b2\", \"b3\").\n",
    "        model_mapping (dict): A dictionary mapping model names to their corresponding classes and weights.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The loaded EfficientNet model.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the model name is not supported.\n",
    "    \"\"\"\n",
    "    # Check if the model name is valid\n",
    "    if model_name not in model_mapping:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}. Supported models are: {list(model_mapping.keys())}\")\n",
    "\n",
    "    # Get the model class and weights from the mapping\n",
    "    model_class_name, weights = model_mapping[model_name]\n",
    "    model_class = getattr(models, model_class_name)\n",
    "\n",
    "    if pretrained:\n",
    "        # Load the model with pretrained weights\n",
    "        effnet = model_class(weights=weights)\n",
    "    else:\n",
    "        effnet = model_class(weights=None)\n",
    "    return effnet\n",
    "\n",
    "\n",
    "try:\n",
    "    effnet = load_efficientnet(model_name, MODEL_MAPPING, pretrained=pretrained)\n",
    "    print(f\"Successfully loaded EfficientNet {model_name}.\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "block0 = list(effnet.features.children())[0]\n",
    "block1 = list(effnet.features.children())[1]\n",
    "block2 = list(effnet.features.children())[2]\n",
    "block3 = list(effnet.features.children())[3]\n",
    "block4 = list(effnet.features.children())[4]\n",
    "block5 = list(effnet.features.children())[5]\n",
    "block6 = list(effnet.features.children())[6]\n",
    "block7 = list(effnet.features.children())[7]\n",
    "block8 = list(effnet.features.children())[8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dNormActivation(\n",
       "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): SiLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dNormActivation(\n",
       "  (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): SiLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TruncatedEffNet(nn.Module):\n",
    "    def __init__(self, effnet, num_classes, removed_layers, batch_size, image_size):\n",
    "        super(TruncatedEffNet, self).__init__()\n",
    "\n",
    "        # Truncate the EfficientNet backbone\n",
    "        layers = 9 - removed_layers\n",
    "        self.effnet_truncated = nn.Sequential(*list(effnet.features.children())[:layers])\n",
    "\n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Dynamically calculate the input size for the fully connected layer\n",
    "        with torch.no_grad():  # Disable gradient tracking for this forward pass\n",
    "            dummy_input = torch.randn(batch_size, 3, image_size, image_size)  # Example input (batch_size=1, channels=3, height=224, width=224)\n",
    "            dummy_output = self.effnet_truncated(dummy_input)\n",
    "            dummy_output = self.global_avg_pool(dummy_output)\n",
    "            fc_input_size = dummy_output.view(dummy_output.size(0), -1).size(1)  # Flatten and get the size\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(.2),\n",
    "            nn.Linear(fc_input_size, num_classes)\n",
    "        )\n",
    "\n",
    "        self.fc_lrelu = nn.Sequential(\n",
    "                    nn.Linear(fc_input_size, 128),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.Dropout(0.2),\n",
    "                    nn.Linear(128, num_classes)\n",
    "                    )   \n",
    "        # Define the fully connected layer\n",
    "        self.fc = nn.Linear(fc_input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.effnet_truncated(x)  # Extract features\n",
    "        x = self.global_avg_pool(x)  # Pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        # x = self.classifier(x)  # Classification\n",
    "        x = self.fc_lrelu(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model with the truncated backbone\n",
    "model = TruncatedEffNet(effnet, num_classes=2, removed_layers=0, batch_size=batch_size, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=False)\n",
       "  (1): Linear(in_features=1280, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnet.classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
