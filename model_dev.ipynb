{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from poutyne import Model, CSVLogger\n",
    "from poutyne.framework import ModelCheckpoint, EarlyStopping, plot_history\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pandas as pd\n",
    "from custom_lib.custom_models.basic_nn import NeuralNetwork\n",
    "from custom_lib.data_prep import data_transformation_pipeline, data_loader\n",
    "import matplotlib as plt\n",
    "import torchvision.models as models\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuneable Params\n",
    "lr = 1e-3\n",
    "\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Define a model name (e.g., \"model1\")\n",
    "model_name = \"custom_reduction_1_b0\"\n",
    "\n",
    "save_logs = True\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "image_size = 224\n",
    "rotate_angle=None\n",
    "horizontal_flip_prob=None\n",
    "brightess_contrast=None\n",
    "gaussian_blur=None\n",
    "normalize=False\n",
    "seed = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6177, Validation size: 772, Test size: 773\n"
     ]
    }
   ],
   "source": [
    "train_transform = data_transformation_pipeline(image_size = image_size,\n",
    "                                               rotate_angle=rotate_angle,\n",
    "                                               horizontal_flip_prob=horizontal_flip_prob,\n",
    "                                               gaussian_blur=gaussian_blur,\n",
    "                                               normalize=normalize,\n",
    "                                               is_train=True)\n",
    "test_transform = data_transformation_pipeline(image_size = image_size,\n",
    "                                               rotate_angle=rotate_angle,\n",
    "                                               horizontal_flip_prob=horizontal_flip_prob,\n",
    "                                               gaussian_blur=gaussian_blur,\n",
    "                                               normalize=normalize,\n",
    "                                               is_train=False)\n",
    "val_transform = data_transformation_pipeline(image_size = image_size,\n",
    "                                               rotate_angle=rotate_angle,\n",
    "                                               horizontal_flip_prob=horizontal_flip_prob,\n",
    "                                               gaussian_blur=gaussian_blur,\n",
    "                                               normalize=normalize,\n",
    "                                               is_train=False)\n",
    "\n",
    "train_loader , val_loader, test_loader, num_classes = data_loader(data_dir, \n",
    "                                                     train_transform=train_transform,\n",
    "                                                     test_transform=test_transform,\n",
    "                                                     val_transform=val_transform,\n",
    "                                                     seed=seed\n",
    "                                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Else statement to determine if the user has passed a custom model or a prebuilt model.\n",
    "# If the model_name contains the word custom, the code extracts the version letter and number\n",
    "# and passes the proper configuration to the model\n",
    "if (\"custom\" in model_name):\n",
    "    from custom_lib.custom_models.custom_eff_net import define_custom_eff_net\n",
    "    import re\n",
    "\n",
    "    efficient_net_config = {\n",
    "        # tuple of width multiplier, depth multiplier, resolution, and Survival Prob for\n",
    "        # each efficientnet version\n",
    "        \"b0\" : (1.0, 1.0, 224, 0.2),\n",
    "        \"b1\" : (1.0, 1.1, 240, 0.2),\n",
    "        \"b2\" : (1.1, 1.2, 260, 0.3),\n",
    "        \"b3\" : (1.2, 1.4, 300, 0.3),\n",
    "        \"b4\" : (1.4, 1.8, 380, 0.4),\n",
    "        \"b5\" : (1.6, 2.2, 456, 0.4),\n",
    "        \"b6\" : (1.8, 2.6, 528, 0.5),\n",
    "        \"b7\" : (2.0, 3.1, 600, 0.5)\n",
    "    }\n",
    "\n",
    "    model = define_custom_eff_net(efficient_net_config=efficient_net_config, num_classes=num_classes, model_name=model_name, device=device)\n",
    "\n",
    "else:\n",
    "    model_class = getattr(models, model_name, None)\n",
    "\n",
    "    if model_class is None:\n",
    "        raise ValueError(f\"Model '{model_name}' is not available in torchvision.models.\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model = model_class(pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compound scaling factors for efficient-net family.\n",
    "\n",
    "\n",
    "# 6. Wrap the model with Poutyne\n",
    "poutyne_model = Model(\n",
    "    model,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=lr),\n",
    "    loss_function=nn.CrossEntropyLoss(),\n",
    "    batch_metrics=['accuracy'],\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1 Step:  87/194  44.85% |████████▉           |ETA: 29.13s loss: 0.649929 acc: 68.750000   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x118ec9800>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayw1327/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/ayw1327/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1568, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 947, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 7. Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mpoutyne_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     21\u001b[0m run_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/poutyne/framework/model.py:610\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, train_generator, valid_generator, epochs, steps_per_epoch, validation_steps, batches_per_step, initial_epoch, verbose, progress_options, callbacks)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_generator_n_batches_per_step(epoch_iterator, callback_list, batches_per_step)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_generator_one_batch_per_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mepoch_logs\n",
      "File \u001b[0;32m~/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/poutyne/framework/model.py:681\u001b[0m, in \u001b[0;36mModel._fit_generator_one_batch_per_step\u001b[0;34m(self, epoch_iterator, callback_list)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_training_mode(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, (x, y) \u001b[38;5;129;01min\u001b[39;00m train_step_iterator:\n\u001b[0;32m--> 681\u001b[0m         step\u001b[38;5;241m.\u001b[39mloss, step\u001b[38;5;241m.\u001b[39mbatch_metrics, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m         step\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m get_batch_size(x, y)\n\u001b[1;32m    684\u001b[0m train_step_iterator\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_loss()\n",
      "File \u001b[0;32m~/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/poutyne/framework/model.py:697\u001b[0m, in \u001b[0;36mModel._fit_batch\u001b[0;34m(self, x, y, callback, step, return_pred, convert_to_numpy)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    693\u001b[0m loss_tensor, batch_metrics, pred_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss_and_metrics(\n\u001b[1;32m    694\u001b[0m     x, y, return_loss_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_pred\u001b[38;5;241m=\u001b[39mreturn_pred, convert_to_numpy\u001b[38;5;241m=\u001b[39mconvert_to_numpy\n\u001b[1;32m    695\u001b[0m )\n\u001b[0;32m--> 697\u001b[0m \u001b[43mloss_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_backward_end(step)\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = None\n",
    "\n",
    "# if save_logs == True:\n",
    "#     # Callback: Save the best model based on validation accuracy\n",
    "#     checkpoint = ModelCheckpoint(f\"{results_dir}/best_model.pth\", monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "#     # Callback: Stop training early if validation accuracy doesn't improve for 5 epochs\n",
    "#     early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "#     # Set up the logger\n",
    "#     csv_logger = CSVLogger(f\"{results_dir}/training_logs.csv\")\n",
    "\n",
    "#     callbacks = [checkpoint, early_stopping, csv_logger]\n",
    "\n",
    "start_time = time.time()\n",
    "# 7. Train the model\n",
    "history = poutyne_model.fit_generator(train_loader, val_loader, epochs=epochs, verbose=True,\n",
    "                            callbacks = callbacks)\n",
    "end_time = time.time()\n",
    "\n",
    "run_time = end_time - start_time\n",
    "\n",
    "print(f\"Model training took {run_time / 60} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test steps: 13 28.14s test_loss: 0.926859 test_acc: 63.001294                                  \n",
      "Test metrics: (0.9268594477494352, 63.001293685735426)\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the model\n",
    "test_metrics = poutyne_model.evaluate_generator(test_loader)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
