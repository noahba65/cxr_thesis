{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuneable Params\n",
    "lr = 1e-3\n",
    "data_dir = \"data_3_class\"\n",
    "model_name = \"b0\"\n",
    "save_logs = True\n",
    "epochs = 100\n",
    "rotate_angle=None\n",
    "horizontal_flip_prob=None\n",
    "brightess_contrast=None\n",
    "gaussian_blur=None\n",
    "normalize=True\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "results_folder_name = \"3_class_results_leaky\"\n",
    "truncated_layers = 0\n",
    "bootstrap_n = 1000\n",
    "pretrained = True\n",
    "image_size = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded EfficientNet b0.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import EfficientNet_B0_Weights, EfficientNet_B1_Weights, EfficientNet_B2_Weights, EfficientNet_B3_Weights\n",
    "import pandas as pd\n",
    "\n",
    "# Define the model mapping as a constant (outside the function)\n",
    "MODEL_MAPPING = {\n",
    "    \"b0\": (\"efficientnet_b0\", EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
    "    \"b1\": (\"efficientnet_b1\", EfficientNet_B1_Weights.IMAGENET1K_V1),\n",
    "    \"b2\": (\"efficientnet_b2\", EfficientNet_B2_Weights.IMAGENET1K_V1),\n",
    "    \"b3\": (\"efficientnet_b3\", EfficientNet_B3_Weights.IMAGENET1K_V1),\n",
    "}\n",
    "\n",
    "def load_efficientnet(model_name, model_mapping, pretrained):\n",
    "    \"\"\"\n",
    "    Load an EfficientNet model based on the provided model name and model mapping.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the EfficientNet model (e.g., \"b0\", \"b1\", \"b2\", \"b3\").\n",
    "        model_mapping (dict): A dictionary mapping model names to their corresponding classes and weights.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The loaded EfficientNet model.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the model name is not supported.\n",
    "    \"\"\"\n",
    "    # Check if the model name is valid\n",
    "    if model_name not in model_mapping:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}. Supported models are: {list(model_mapping.keys())}\")\n",
    "\n",
    "    # Get the model class and weights from the mapping\n",
    "    model_class_name, weights = model_mapping[model_name]\n",
    "    model_class = getattr(models, model_class_name)\n",
    "\n",
    "    if pretrained:\n",
    "        # Load the model with pretrained weights\n",
    "        effnet = model_class(weights=weights)\n",
    "    else:\n",
    "        effnet = model_class(weights=None)\n",
    "    return effnet\n",
    "\n",
    "\n",
    "try:\n",
    "    effnet = load_efficientnet(model_name, MODEL_MAPPING, pretrained=pretrained)\n",
    "    print(f\"Successfully loaded EfficientNet {model_name}.\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "block0 = list(effnet.features.children())[0]\n",
    "block1 = list(effnet.features.children())[1]\n",
    "block2 = list(effnet.features.children())[2]\n",
    "block3 = list(effnet.features.children())[3]\n",
    "block4 = list(effnet.features.children())[4]\n",
    "block5 = list(effnet.features.children())[5]\n",
    "block6 = list(effnet.features.children())[6]\n",
    "block7 = list(effnet.features.children())[7]\n",
    "block8 = list(effnet.features.children())[8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dNormActivation(\n",
       "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): SiLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "  )\n",
       "  (1): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "  )\n",
       "  (1): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "  )\n",
       "  (1): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "  )\n",
       "  (2): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "  )\n",
       "  (1): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "  )\n",
       "  (2): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "  )\n",
       "  (1): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "  )\n",
       "  (2): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "  )\n",
       "  (3): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MBConv(\n",
       "    (block): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): SqueezeExcitation(\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): SiLU(inplace=True)\n",
       "        (scale_activation): Sigmoid()\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dNormActivation(\n",
       "  (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): SiLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import Conv2dNormActivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TruncatedEffNet(nn.Module):\n",
    "    def __init__(self, effnet, num_classes, removed_layers, batch_size, image_size):\n",
    "        super(TruncatedEffNet, self).__init__()\n",
    "\n",
    "        # Truncate the EfficientNet backbone\n",
    "        layers = 9 - removed_layers\n",
    "        self.effnet_truncated = nn.Sequential(*list(effnet.features.children())[:layers])\n",
    "\n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Dynamically calculate the input size for the fully connected layer\n",
    "        with torch.no_grad():  # Disable gradient tracking for this forward pass\n",
    "            dummy_input = torch.randn(batch_size, 3, image_size, image_size)  # Example input (batch_size=1, channels=3, height=224, width=224)\n",
    "            dummy_output = self.effnet_truncated(dummy_input)\n",
    "            activation_input_size = dummy_output.view(dummy_output.size(0), -1).size(1)\n",
    "            # dummy_output = self.global_avg_pool(dummy_output)\n",
    "            # fc_input_size = dummy_output.view(dummy_output.size(0), -1).size(1)  # Flatten and get the size\n",
    "\n",
    "        self.activation = Conv2dNormActivation(activation_input_size, \n",
    "                                               out_channels=112,\n",
    "                                               kernel_size=(1, 1),\n",
    "                                               stride=(1, 1),\n",
    "                                               bias=False,\n",
    "                                               norm_layer=nn.BatchNorm2d,\n",
    "                                               activation_layer=nn.SiLU   \n",
    "                                               )\n",
    "        \n",
    "\n",
    "#          Conv2dNormActivation(\n",
    "#                 lastconv_input_channels,\n",
    "#                 lastconv_output_channels,\n",
    "#                 kernel_size=1,\n",
    "#                 norm_layer=norm_layer,\n",
    "#                 activation_layer=nn.SiLU,\n",
    "# )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(.2),\n",
    "            nn.Linear(112, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.effnet_truncated(x)  # Extract features\n",
    "        x = self.activation(x)\n",
    "        x = self.global_avg_pool(x)  # Pooling\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model with the truncated backbone\n",
    "model = TruncatedEffNet(effnet, num_classes=2, removed_layers=4, batch_size=batch_size, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TruncatedEffNet' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241m.\u001b[39mchildren()\n",
      "File \u001b[0;32m~/Documents/GitHub/cxr_thesis/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TruncatedEffNet' object has no attribute 'features'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnet.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_stats(model, batch_size, image_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    \"\"\"\n",
    "    Computes the FLOPs and number of parameters for a given model.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        batch_size (int): The batch size for the dummy input.\n",
    "        image_size (int): The height and width of the input image.\n",
    "        device (str): The device to perform computations on (\"cuda\" or \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (GFLOPs, parameters)\n",
    "    \"\"\"\n",
    "    model.to(device)  # Move model to the specified device\n",
    "    dummy_input = torch.randn(batch_size, 3, image_size, image_size).to(device)\n",
    "\n",
    "    flops, params = profile(model, inputs=(dummy_input,))\n",
    "    gflops = flops / 1e9  # Convert to GFLOPs\n",
    "\n",
    "    print(f\"GFLOPs: {gflops:.3f}\")\n",
    "    print(f\"Parameters: {params:,}\")  # Add commas for readability\n",
    "\n",
    "    return gflops, params     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.414\n",
      "Parameters: 4,171,774.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.394\n",
      "Parameters: 3,636,734.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.363\n",
      "Parameters: 2,903,118.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.270\n",
      "Parameters: 866,530.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.180\n",
      "Parameters: 319,286.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.134\n",
      "Parameters: 71,236.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.091\n",
      "Parameters: 22,548.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "GFLOPs: 0.025\n",
      "Parameters: 4,810.0\n"
     ]
    }
   ],
   "source": [
    "gflops_list = []\n",
    "params_list = []\n",
    "truncated_blocks = []\n",
    "\n",
    "for i in range(8):\n",
    "    \n",
    "    model = TruncatedEffNet(effnet, num_classes=2, removed_layers=i, batch_size=batch_size, image_size=image_size)\n",
    "\n",
    "    gflops, params =  compute_model_stats(model=model, batch_size=1, image_size=224)\n",
    "\n",
    "    gflops_list.append(gflops)\n",
    "    params_list.append(params)\n",
    "    truncated_blocks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truncated_blocks</th>\n",
       "      <th>gflops</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.414029</td>\n",
       "      <td>4171774.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.393537</td>\n",
       "      <td>3636734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.363422</td>\n",
       "      <td>2903118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.269526</td>\n",
       "      <td>866530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>319286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.133515</td>\n",
       "      <td>71236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.091302</td>\n",
       "      <td>22548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>4810.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   truncated_blocks    gflops     params\n",
       "0                 0  0.414029  4171774.0\n",
       "1                 1  0.393537  3636734.0\n",
       "2                 2  0.363422  2903118.0\n",
       "3                 3  0.269526   866530.0\n",
       "4                 4  0.179930   319286.0\n",
       "5                 5  0.133515    71236.0\n",
       "6                 6  0.091302    22548.0\n",
       "7                 7  0.025492     4810.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'truncated_blocks': truncated_blocks, 'gflops': gflops_list, 'params': params_list})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
